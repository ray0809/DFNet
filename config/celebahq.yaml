dataname: 'celebahq'
 
# 分布式参数，gpu>1的话分布式会自动开启
single: 1  # 决定是否单卡训练，否则会开启单机多卡
seed: 2020
port: '23455'
sync_bn: False   # 多卡的bn是否统一计算
mix_precision: False
 
input_size: 256   # 训练参数，注意这里的batch_size，指的是单卡的batch，分布式每个gpu都是该batch大小
batch_size: 14
num_workers: 8
epochs: 300
lr_decay_epoch: 280
lr_decay_ratio: 0.1
vis_img_step: 1000
checkpoint_step: 3000
flist_train: './flist/Celeba-HQ_train.txt'
flist_test: './flist/Celeba-HQ_test.txt'


fine_tune: True
checkpoint: './logs/celebahq/simpler/2020-05-28-12-50-16/ckpt/4.pth'



tensorboard: True
logdir: './logs'   # tensorboard，训练过程中的loss曲线图，中间结果图像可视化
mask_type: 'simpler'   # 三种非规则涂抹方式: pconv, free-from, simpler
  
# 模型参数
modelParams:
  c_img: 3
  c_mask: 1
  c_alpha: 3
  mode: 'nearest'
  norm: 'batch'
  act_en: 'relu'
  act_de: 'leaky_relu'
  en_ksize: [7, 5, 5, 3, 3, 3, 3, 3]
  de_ksize: [3, 3, 3, 3, 3, 3, 3, 3]
  blend_layers: [0, 1, 2, 3, 4, 5]
  freeze_en_bn: False

  
# 优化器参数
optimizer:
  name: 'Adam'
  lr: 0.0002
  beta1: 0.5
  beta2: 0.999




# 损失参数
loss:
  w_l1: 6.
  w_percep: 0.1
  w_style: 240.
  structure_layers: [0, 1, 2, 3, 4, 5]
  texture_layers: [0, 1, 2]

